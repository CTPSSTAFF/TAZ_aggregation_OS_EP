---
title: "TAZ_aggregation"
author: "Joe Delorto"
format: 
  html:
    self-contained: true
warning: false
message: false
---

This document will detail the process of aggregating CTPS's data on open space/park access and essential places to the transportation analysis zone (TAZ) level.

As required by federal regulations, the Boston Region MPO's long-range transportation plan (LRTP), _Destination 2050_, will include an equity analysis of the projects in the MPO's Recommended Plan. For _Destination 2050_, this will include information on how, if at all, the Recommended Plan projects will change access to these places (as well as jobs, higher education, and healthcare facilities) and how these changes might have disproportionate impacts or disparate burdens (DI/DB) on minority and low-income populations as compared to nonminority and non-low-income populations, respectively.

For _Destination 2050_, CTPS developed a new regional travel demand model, Travel Demand Model 2023 (TDM23). Similar to previous versions of TDM and other regional travel demand models, TDM23 uses a unit of geographic analysis known as the TAZ. Thus, to measure access to open spaces and essential places, we must have TAZ-level information on access to these places.

Let's load the necessary packages to enable this analysis.

```{r}
library(sf)
library(tidyverse)
library(viridis)
```

To begin, we load the shapefile that contains the model area's TAZs and filter them down to the Boston MPO region.

```{r}
taz_shapes <- sf::read_sf("data/TAZ_shapefiles/CTPS_TDM23_TAZ_2017g_v202303.shp")

mpo_tazs <- taz_shapes %>%
  filter(mpo == "BRMPO")
```

## Parks and Open Spaces

For the purposes of parks and open spaces, we will be measuring each TAZ's "access" to parks and open spaces by counting the number of park access points in each TAZ. Access points were generated previously and are based on the OpenStreetMap pedestrian and drive networks.

```{r}
open_space_access_points <- sf::read_sf("data/DestinationData.gpkg", layer = "OpenSpaceAccess_PT")
```

```{r}
ggplot(data = open_space_access_points) + 
  geom_sf() 
```

Now we merge the access points with the TAZ layer to associate each access point with the TAZ in which it is located.

```{r}
os_taz_join <- sf::st_intersection(mpo_tazs, open_space_access_points)
```

We then tally the number of access points in each TAZ, keeping only the pertinent information.

```{r}
os_access_points_counted <- os_taz_join %>% 
  count(taz_id) %>% 
  st_drop_geometry()

## show the first few rows as an example of the output
print(head(os_access_points_counted, 10))
```

As shown above, because not every TAZ has an access point inside it, we don't have a clean list of the number of access points inside each TAZ. We need to add in the TAZs with zero counts to get a clean list of every TAZ in the MPO region.
 
```{r}
taz_id <- sort(st_drop_geometry(mpo_tazs)$taz_id)
n <- rep(0, times = length(taz_id))
os_access_points_by_TAZ <- data.frame(taz_id, n)

for (i in 1:nrow(os_access_points_counted)){
  ## i is the row in the incomplete list of TAZs
  ## j is the row in the complete list of TAZs that we're trying to fill
  j <- which(os_access_points_by_TAZ$taz_id == os_access_points_counted$taz_id[i])
  m <- os_access_points_counted[i, 2]
  
  os_access_points_by_TAZ[j, 2] <- m
}

print(head(os_access_points_by_TAZ))
```

Now we have a clean list of every TAZ in the Boston MPO region and the number of park/open space access points in each TAZ. Let's map the results:

```{r}
mpo_tazs_with_os_counts <- mpo_tazs %>% 
  left_join(os_access_points_by_TAZ, copy = TRUE)

ggplot(mpo_tazs_with_os_counts, aes(fill = n)) + 
  geom_sf() + 
  scale_fill_viridis_c()
```

For a more illustrative example, let's visit downtown Bostonâ€”specifically, TAZs 1 through 100. The bright yellow TAZ in the middle contains Boston Common and the Public Garden. The green TAZ to its upper left contains the Charles River Esplanade. These are both locations where we would expect to see many park/open space access points.

```{r}
first_few_tazs_os <- mpo_tazs_with_os_counts %>% 
  filter(taz_id <= 100)

ggplot(first_few_tazs_os, aes(fill = n)) + 
  geom_sf() + 
  scale_fill_viridis_c()
```

```{r}
write_csv(os_access_points_by_TAZ, "output/open_space_access_points_by_TAZ.csv")
```

## Essential Places

"Essential places" are clusters each containing at least five essential destinations from at least two of the following categories: healthcare destinations, civic destinations, and food destinations. These clusters are then represented as polygons. For the purposes of our analysis, we will simply be scoring each TAZ by the presence of an essential places polygon, not by the number of polygons that intersect each TAZ.

First, we load the essential places data.

```{r}
essential_places_polygons <- sf::read_sf("data/DestinationData.gpkg", layer = "essentialPlace_Final_POLY")
```

Now, we join the essential places to the TAZ layer, as above.

```{r}
ep_taz_join <- sf::st_intersection(select(mpo_tazs, taz_id), essential_places_polygons)
```

Now we repeat the same process as above to get to a clean list of all TAZs in the MPO region.

```{r}
ep_present <- rep(0, times = length(taz_id))
ep_presence_by_taz <- data.frame(taz_id, ep_present)

for (i in 1:nrow(ep_presence_by_taz)){
  ep_presence_by_taz[i, 2] <- as.integer(ep_presence_by_taz[i, 1] %in% ep_taz_join$taz_id)
}

print(head(ep_presence_by_taz))
```

Same maps as above to verify:

```{r}
mpo_tazs_with_ep_presence <- 
  mpo_tazs %>% left_join(ep_presence_by_taz)
first_few_tazs_ep <- mpo_tazs_with_ep_presence %>% 
  filter(taz_id <= 100)

ggplot(data = mpo_tazs_with_ep_presence, aes(fill = as.logical(ep_present))) +
  geom_sf()

ggplot(data = first_few_tazs_ep, aes(fill = as.logical(ep_present))) +
  geom_sf()
```

And finally, write the output to a .csv.

```{r}
write_csv(ep_presence_by_taz, "output/essential_place_presence_by_TAZ.csv")
```